{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7NaqT/c1xnbQXo/wWCQvv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrianop/ML/blob/main/05_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble learning**\n",
        "\n",
        "Ensemble learning involves combining models to achieve improved results, making it a powerful tool in machine learning.\n",
        "Random Forest is an example of ensemble learning, where multiple decision trees are combined to enhance the model's performance and prevent overfitting.\n",
        "In the context of K-Means clustering, we can utilize different K-means models initialized with various random centroids. Finally, we can aggregate the results through voting to determine the best final outcome."
      ],
      "metadata": {
        "id": "nLZVv6YgzyIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest uses a technique called **bagging**, which stands for bootstrap aggregating. Bagging involves taking random sub-samples of the training data and feeding each sub-sample into different versions of the same model. These models then vote to determine the final result. In the context of Random Forest, many decision trees are trained on random samples of the training data, employing bagging to improve the model's performance.\n",
        "\n",
        "**Boosting** is an alternative approach where subsequent models focus on addressing the areas misclassified by previous models. The idea is to start with a base model and then boost the attributes that are relevant to the misclassified instances. By iteratively training and adjusting models based on the weak points identified in the previous models, boosting aims to improve the overall accuracy.\n",
        "\n",
        "**Bucket of models** involves training multiple models on the same training data and selecting the best-performing model as the final choice.\n",
        "\n",
        "**Stacking**, on the other hand, runs multiple models and combines their results. However, unlike the bucket of models approach where only the winning model is selected, stacking combines the results of all the models to arrive at the final output. This combination of multiple models' predictions can provide improved performance and better decision-making."
      ],
      "metadata": {
        "id": "mILsK9FLSI-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced ensemble learning:\n",
        "\n",
        "* Bayes optimal classifier: Is theoretically the best, but it is impractical\n",
        "Bayesian Parameter Averaging: suceptible to overfitting and often outperformed by the simpler bagging approach.\n",
        "\n",
        "* Bayesian Model Combination: Try to solve all the shortcomings of Bayes optimal classifier and Bayesian Parameter Averaging.\n",
        "\n",
        "* Difficult to do in practice."
      ],
      "metadata": {
        "id": "O_3DMQqXGb9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost**"
      ],
      "metadata": {
        "id": "PogUEhhQID1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost means eXtreme Gradient Boosted trees. We remind that boosting is an ensemble method, which allows us to improve this attributes which are getting worst in our study.\n",
        "XGBoost has several interesting features as:\n",
        "\n",
        "* Regularized boosting, which prevents overfitting.\n",
        "* We can handle missing values automatically. We don't have to think so much.\n",
        "* The proccess running in parallel.\n",
        "* We can do cross-validation in each iteration.\n",
        "* This supports incremental training, so this stop the training of an XGBoost model save it and came back o pick up it later again.\n",
        "* Can plug in your own optimization objectives.\n",
        "* Tree pruning: We remind that pruning refers to the process of reducing the size of a decision tree by removing unnecessary branches and nodes. It is a technique used to prevent overfitting and improve the generalization ability of the tree.\n"
      ],
      "metadata": {
        "id": "4PfTxZFrIIxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning Hyperparameter:\n",
        "* Choose the booster:\n",
        " - gbtree\n",
        " - gblinear\n",
        "* See the what is the objetive of the model:\n",
        " - multi: softmax\n",
        " - multi: softprob\n",
        "* ETA: The biggest knob that we have in XGBoost, this is a learning rate which adjust weight on each step. The default value is 0.3, lower value generates better results. Weights\n",
        "* Max_dept  depht of the tree: If the depth of the tree is niot large enough, you are not able to create a very accurate model, but if this is too large you probably lead to overfitting.\n",
        "* Min_child_weight: use to control overfitting.\n",
        "* look for more hyperparameters.\n"
      ],
      "metadata": {
        "id": "-vkDKwL9PPfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ays-gXRAIGbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example**"
      ],
      "metadata": {
        "id": "9FZoG_0CHqof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we run code in a local storage, we have to install xgboost using `pip install xgboost`.\n",
        "We are going to consider the iris dataset  fromo sklearn which  includes the width and length of the petals and sepals of many Iris flowers.\n"
      ],
      "metadata": {
        "id": "fttsipH0SCKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "type_iris = type(iris)\n",
        "type_iris"
      ],
      "metadata": {
        "id": "waPmYJ7SHs4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20f7df2-86a3-4977-fabd-dc49e0ff65e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame from the iris dataset\n",
        "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df_iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v_dAggHc5Pyv",
        "outputId": "83e1a18f-8e3f-456d-a69b-6aaeb14763e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                  5.1               3.5                1.4               0.2\n",
              "1                  4.9               3.0                1.4               0.2\n",
              "2                  4.7               3.2                1.3               0.2\n",
              "3                  4.6               3.1                1.5               0.2\n",
              "4                  5.0               3.6                1.4               0.2\n",
              "..                 ...               ...                ...               ...\n",
              "145                6.7               3.0                5.2               2.3\n",
              "146                6.3               2.5                5.0               1.9\n",
              "147                6.5               3.0                5.2               2.0\n",
              "148                6.2               3.4                5.4               2.3\n",
              "149                5.9               3.0                5.1               1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-dadde511-2750-424b-a139-5596b4400f45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dadde511-2750-424b-a139-5596b4400f45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-57a38ec8-b3db-40f3-b37c-20a1f442ff63\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57a38ec8-b3db-40f3-b37c-20a1f442ff63')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-57a38ec8-b3db-40f3-b37c-20a1f442ff63 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dadde511-2750-424b-a139-5596b4400f45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dadde511-2750-424b-a139-5596b4400f45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_samples , number_features = iris.data.shape\n",
        "print(f'The number of samples in the array iris is {number_samples} and the amount of features is {number_features}')\n",
        "print(f'The information in the target is: {list(iris.target_names)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhRO0Tv_4fDV",
        "outputId": "672299f2-0a73-4bcc-8077-8b81fa166e76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples in the array iris is 150 and the amount of features is 4\n",
            "The information in the target is: ['setosa', 'versicolor', 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe several properties of the information provided in the Iris dataset. The dataset consists of an array with 150 samples, each representing an iris flower, and four features that describe each sample. Moreover, the information in the dataset is already classified, which means we have target values available. These target values are valuable for training our model and drawing various conclusions based on the dataset.\n",
        "We can see that the kind of iris flowers that we have are:\n",
        "* setosa\n",
        "* versicolor\n",
        "* virginica"
      ],
      "metadata": {
        "id": "n-YsCZFv4fnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the objective is to train a model using the available data, specifically employing XGBoost. To begin the training process, it is essential to split the dataset into two distinct sets: a training set and a test set. The allocation of data between these sets can vary. One common approach is to assign 70% of the data to the training set and the remaining 30% to the test set. Alternatively, an 80% to 20% split can also be considered, where 80% of the data is utilized for training, and the remaining 20% is set aside for testing the model's performance. The choice of the specific split ratio depends on various factors, including the dataset's size and the desired evaluation strategy."
      ],
      "metadata": {
        "id": "61o5SZ937bPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting dataset: train = 70 % and test = 30 %\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "f9aQUSG77Z-f"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}