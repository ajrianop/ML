{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGi1GQRvGJfjmS2ItXFw0l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrianop/ML/blob/main/04_DecisionTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision trees**"
      ],
      "metadata": {
        "id": "eKrRKeHXsI9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Entropy**"
      ],
      "metadata": {
        "id": "yzJ47yQTsMgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy is a fundamental concept in thermodynamics that measures the disorder or randomness of a physical system. In the realm of data science, entropy can also be used to measure the disorder or randomness of a data set. The entropy of a data set is zero when the data is completely ordered and consistent, and increases as the data becomes more random and varied. As a data scientist, understanding the entropy of a data set can provide valuable insights into its structure and allow for more accurate analysis and predictions. It is also important to note that entropy can also be used in information theory, as a measure of uncertainty in a random variable.\n",
        "\n",
        "**How to compute entropy?**\n",
        "$$H=-p_1\\ln p_1--p_2\\ln p_2-\\cdots -p_n\\ln p_n,$$\n",
        "where $p_i$ represent the proportion of the data."
      ],
      "metadata": {
        "id": "kYq7sARusQDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree**"
      ],
      "metadata": {
        "id": "IBI-JoHnodR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree gives us a flowchart which help us to make some decision according to a classification description.\n",
        "Some examples to use decision tree can be related to weather, where we can describe if the day will be rainy or sunny. There are other examples as:\n",
        "1. medical diagnosis, which by means symptoms and test results we can lead to a diagnosis.\n",
        "2. Quality control, which allows us identify causes or defects in any manufacturing process\n",
        "3. Filter resumes by analyzing the historical hiring data and classify them based on a pre-established database that contains relevant attributes for the job position."
      ],
      "metadata": {
        "id": "r4M0Sz0Pog4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How the algorithm works?**\n",
        "\n",
        "The algorithm operates by identifying relevant attributes and partitioning the data set in a way that reduces the entropy of the input data, repeating this process for each attribute at various levels.\n",
        "\n",
        "**Problems:**\n",
        "\n",
        "The algorithm is very prompt to overfitting, so to avoid this problem there exists a technique call random forest, which works as a collection of trees, where each tree is trainged on a random subset of the data. In order to conclude, the final output will be the average of each of our output results of all the decision trees."
      ],
      "metadata": {
        "id": "0f0Rq9M4wTnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTsNfVFAsFwm"
      },
      "outputs": [],
      "source": []
    }
  ]
}